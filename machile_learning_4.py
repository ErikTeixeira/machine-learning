# -*- coding: utf-8 -*-
"""machile learning - 4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D1AiOpoyhwV3NQ3QhDJSLT0RuVs1Iylk
"""

# não precisa nessa versão do colab

# importar o graphviz
# tem que ser colado graphviz==0.10
# !pip install graphviz==0.10

# instalar o programa que o graphviz usa - no linux, mac, windows ...
# linux
!apt-get install graphviz

import pandas as pd

uri = "https://gist.githubusercontent.com/guilhermesilveira/4d1d4a16ccbf6ea4e0a64a38a24ec884/raw/afd05cb0c796d18f3f5a6537053ded308ba94bf7/car-prices.csv"

dados = pd.read_csv(uri)
dados.head()

a_renomear = {
    'mileage_per_year' : 'milhas_por_ano',
    'model_year' : 'ano_do_modelo',
    'price' : 'preco',
    'sold' :'vendido'
}
dados = dados.rename(columns=a_renomear)
dados.head()

# 1 - yes   |   0 - no

a_trocar = {
    'no': 0,
    'yes': 1
}

# sobreescrever a coluna vendidos
dados.vendido = dados.vendido.map(a_trocar)
dados.head()

# criar a coluna idade_modelo

# pegar o ano atual
from datetime import datetime

ano_atual = datetime.today().year

dados["idade_modelo"] = ano_atual - dados.ano_do_modelo
dados.head()

# converter milhas para km, criando uma nova coluna

dados["km_por_ano"] = dados.milhas_por_ano * 1.60934
dados.head()

# tirar colunas
# drop - funciona para linhas, para colunas tem que falar o eixo

dados = dados.drop( columns = ["Unnamed: 0", "milhas_por_ano", "ano_do_modelo"], axis = 1)
dados.head()

# separar X e o Y

x = dados[["preco", "idade_modelo", "km_por_ano"]]
y = dados["vendido"]

# classificação do Linear SVC

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score

SEED = 10
np.random.seed(SEED)
treino_x, teste_x, treino_y, teste_y = train_test_split(x, y, test_size = 0.25,
                                                         stratify = y)
print("Treinaremos com %d elementos e testaremos com %d elementos" % (len(treino_x), len(teste_x)))

modelo = LinearSVC()
modelo.fit(treino_x, treino_y)
previsoes = modelo.predict(teste_x)

acuracia = accuracy_score(teste_y, previsoes) * 100
print("A acurácia foi %.2f%%" % acuracia)

"""## Escolher qual base line ficou melhor - a stratified ou a mostfrequent"""

# base line
# sklearn já possui um proprio  -  dummy classifier

from sklearn.dummy import DummyClassifier    # parametros - strategy, random_state, constant
                                                                # o np.random.seed(SEED) - serve para ele tmb
dummy_stratified = DummyClassifier()      # o padrao do strategy e stratified

# treinar o dummy
dummy_stratified.fit(treino_x, treino_y)

# já da pra calcular a acuracia, não precisa do accuracy score para o dummy
# tem que passar o x e o y
acuracia = dummy_stratified.score(teste_x, teste_y) * 100

print("A acurácia foi %.2f%%" % acuracia)

# previsoes = dummy_stratified.predict(teste_x)
# acuracia = accuracy_score(teste_y, previsoes) * 100

# base line
from sklearn.dummy import DummyClassifier

dummy_mostfrequent = DummyClassifier()      # outro parametro do strategy e mostfrequent

# treinar o dummy
dummy_mostfrequent.fit(treino_x, treino_y)
acuracia = dummy_mostfrequent.score(teste_x, teste_y) * 100

print("A acurácia foi %.2f%%" % acuracia)

"""## Teste com o SVC"""

# separar X e o Y

x = dados[["preco", "idade_modelo", "km_por_ano"]]
y = dados["vendido"]

# classificação do SVC
from sklearn.preprocessing import StandardScaler

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

SEED = 5
np.random.seed(SEED)
raw_treino_x, raw_teste_x, treino_y, teste_y = train_test_split(x, y, test_size = 0.25,
                                                         stratify = y)
print("Treinaremos com %d elementos e testaremos com %d elementos" % (len(treino_x), len(teste_x)))


# NÃO USAR O CÓDIGO DO LINEAR SVC - PRECISA REESCALAR PARA USAR O SVC
scaler = StandardScaler()
scaler.fit(treino_x, treino_y)
treino_x = scaler.transform(raw_treino_x)
teste_x = scaler.transform(raw_teste_x)

modelo = SVC()
modelo.fit(treino_x, treino_y)
previsoes = modelo.predict(teste_x)

acuracia = accuracy_score(teste_y, previsoes) * 100
print("A acurácia foi %.2f%%" % acuracia)

"""# Algoritmos de Decisões  ---  DecisionTreeClassifier
### Mostra as decisões que foram tomadas para chegar no resultado
#### NÃO PRECISA REESCALAR
"""

# separar X e o Y

x = dados[["preco", "idade_modelo", "km_por_ano"]]
y = dados["vendido"]

# classificação do DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler

import numpy as np
from sklearn.model_selection import train_test_split
# tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

SEED = 5
np.random.seed(SEED)
raw_treino_x, raw_teste_x, treino_y, teste_y = train_test_split(x, y, test_size = 0.25,
                                                         stratify = y)
print("Treinaremos com %d elementos e testaremos com %d elementos" % (len(treino_x), len(teste_x)))


# mudar aqui tmb      -      max depth - tamanho maximo da divisao do grafico
modelo = DecisionTreeClassifier( max_depth = 3 )
modelo.fit(raw_treino_x, treino_y)
previsoes = modelo.predict(raw_teste_x)

acuracia = accuracy_score(teste_y, previsoes) * 100
print("A acurácia foi %.2f%%" % acuracia)

"""## Exportar a visualização gráfica desta "Árvore"
"""

from sklearn.tree import export_graphviz
import graphviz   # visualizar o grafico

# out_file = None   -  para falar que não vai salvar em um arquivo
# export_graphviz  -  devolve um formato de um grafico

# colocar no parametro nome do X sendo as colunas
features = x.columns
dot_data = export_graphviz(modelo, out_file = None,
                           filled = True, rounded = True,   # colocar cor e deixar arredondado
                           feature_names = features,
                           class_names = ["não", "sim"])    # mapear o não (0) e o sim (1)

# faz o gráfico
grafico = graphviz.Source(dot_data)

grafico

# SAMPLES - quantidade de elementos
# deicisao que a ávore vai tomando de quebrar ou não e baseada no GINI