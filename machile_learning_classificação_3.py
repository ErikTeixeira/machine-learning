# -*- coding: utf-8 -*-
"""machile learning - classificação - 3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15og2Y4uCmE2eksZmtbXO9E2wsAHHZVQD
"""

# Atualizar a biblioteca seaborn   -  para usar o scatterplot
!pip install seaborn==0.9.0

import pandas as pd

uri = "https://gist.githubusercontent.com/guilhermesilveira/1b7d5475863c15f484ac495bd70975cf/raw/16aff7a0aee67e7c100a2a48b676a2d2d142f646/projects.csv"

dados = pd.read_csv(uri)

dados.head()

# unfinished -> 1  =  não finalizado

a_renomear = {
    "expected_hours" : "horas_esperadas",
    "price" : "preco",
    "unfinished" : "nao_finalizado"
}

dados = dados.rename(columns = a_renomear)
dados.head()

# trocar o 1 pelo 0 na não finalizado  -  para criar uma nova coluna

troca = {
    0 : 1,
    1 : 0
}

dados["finalizado"] = dados.nao_finalizado.map(troca)
dados.head()

# Desenho dos dados

import seaborn as sns

sns.scatterplot(x = "horas_esperadas", y = "preco", data = dados)

# Pintar a bolinha de uma cor diferente se finalizou ou não

sns.scatterplot(x = "horas_esperadas", y = "preco", hue = "finalizado", data = dados)

# user o col para mostrar em 2 diferentes
# relplot

sns.relplot(x = "horas_esperadas", y = "preco", hue = "finalizado", col = "finalizado", data = dados)

x = dados[["horas_esperadas", "preco"]]
y = dados["finalizado"]

from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score

SEED = 10

np.random.seed(SEED)      # não precisa mais passar para ninguem a seed

treino_x, teste_x, treino_y, teste_y = train_test_split(x, y, test_size = 0.25, stratify = y)

print("Treinaremos com %d elementos e testaremos com %d elementos" % (len(treino_x), len(teste_x)))

# LinearSVC() - tem o random nos parametros - não precisa passar por causa do np.random
modelo = LinearSVC()
modelo.fit(treino_x, treino_y)
previsoes = modelo.predict(teste_x)

acuracia = accuracy_score(teste_y, previsoes) * 100
print("A acurácia foi %.2f%%" % acuracia)

"""## Ter um algoritmo de base

O algoritmo base converte uma coluna deixando somente 0 ou somente 1. Com isso nós implementamos o teste do algoritmo e obtemos o resultado.
"""

# numpy - biblioteca que gera matrizes, trabalha com matrizes

import numpy as np

# algoritimo de base
# meta e conseguir ser melhor que está base

# gerar 540 ums  -  seria chutar 1 para tudo - que daria 52.59%  -  um pouco pior do que treinar
previsoes_base = np.ones(540)

acuracia = accuracy_score(teste_y, previsoes_base) * 100
print("A acurácia da baseline foi %.2f%%" % acuracia)

# analizar o teste x

sns.scatterplot(x = "horas_esperadas", y = "preco", hue = teste_y, data = teste_x)

# analize em 2 dimensoes  - cada pixel do grafico e passado para o algoritmo para ele pintar de uma cor, e falar se seria finalizado ou não

x_min = teste_x.horas_esperadas.min()
x_max = teste_x.horas_esperadas.max()

y_min = teste_x.preco.min()
y_max = teste_x.preco.max()

pixels = 100

# dividiu o espaço do 0 até o 100 em 100 pedaços, foi somando cada espaço proporcionalmente até chegar no final
eixo_x = np.arange(x_min, x_max, (x_max - x_min) / pixels)

eixo_y = np.arange(y_min, y_max, (y_max - y_min) / pixels)

# criar um grid
xx, yy = np.meshgrid(eixo_x, eixo_y)           #  ainda não está mesclado

# mesclar
pontos = np.c_[xx.ravel(), yy.ravel()]      # formou os pares

Z = modelo.predict(pontos)

# redimensionar o Z de acordo com o xx
Z = Z.reshape(xx.shape)

Z

# plotar
import matplotlib.pyplot as plt

# Z - cor definida pelo Z
# curva do algoritimo
plt.contourf(xx, yy, Z, alpha = 0.3)

# pontos jogados
# definir a cor e o  -  c
# definir o tamanho(size) e o  -  s
plt.scatter(teste_x.horas_esperadas, teste_x.preco, c = teste_y, s = 5)

#   DECISION BOUNDARY   -   CURVA DE DESISAO

"""# Usar o que é apenas SVC  -  não linear"""

from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

SEED = 10

np.random.seed(SEED)      # não precisa mais passar para ninguem a seed

treino_x, teste_x, treino_y, teste_y = train_test_split(x, y, test_size = 0.25, stratify = y)

print("Treinaremos com %d elementos e testaremos com %d elementos" % (len(treino_x), len(teste_x)))

# LinearSVC() - tem o random nos parametros - não precisa passar por causa do np.random
modelo = SVC(gamma='auto')
modelo.fit(treino_x, treino_y)
previsoes = modelo.predict(teste_x)

acuracia = accuracy_score(teste_y, previsoes) * 100
print("A acurácia foi %.2f%%" % acuracia)

x_min = teste_x.horas_esperadas.min()
x_max = teste_x.horas_esperadas.max()
y_min = teste_x.preco.min()
y_max = teste_x.preco.max()


pixels = 100
eixo_x = np.arange(x_min, x_max, (x_max - x_min) / pixels)
eixo_y = np.arange(y_min, y_max, (y_max - y_min) / pixels)


xx, yy = np.meshgrid(eixo_x, eixo_y)
pontos = np.c_[xx.ravel(), yy.ravel()]


Z = modelo.predict(pontos)
Z = Z.reshape(xx.shape)


import matplotlib.pyplot as plt

plt.contourf(xx, yy, Z, alpha = 0.3)
plt.scatter(teste_x.horas_esperadas, teste_x.preco, c = teste_y, s = 5)

"""-- reescalar"""

# escalas distintas causam um balanço no algoritmo     -  0 -> 30000   0 -> 100

# reescalar tudo para uma faixa parecida
from sklearn.preprocessing import StandardScaler


from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

SEED = 10

np.random.seed(SEED)      # não precisa mais passar para ninguem a seed

# raw - valor original
raw_treino_x, raw_teste_x, treino_y, teste_y = train_test_split(x, y, test_size = 0.25, stratify = y)

print("Treinaremos com %d elementos e testaremos com %d elementos" % (len(treino_x), len(teste_x)))


# pegar os valores de x do treino e criar uma escala nova
scaler = StandardScaler()
# treinar o precesso de escala
scaler.fit(raw_treino_x)
# transformar o treino x, no treino x novo, na escala nova    -   reescala
treino_x = scaler.transform(raw_treino_x)
teste_x = scaler.transform(raw_teste_x)


modelo = SVC(gamma='auto')
modelo.fit(treino_x, treino_y)
previsoes = modelo.predict(teste_x)

acuracia = accuracy_score(teste_y, previsoes) * 100
print("A acurácia foi %.2f%%" % acuracia)

# treino_x          -   é agora um array e arrays
# raw_treino_x      -   era uma pandas   -  que tinha horas_esperadas e preco de forma diferente

# todas as linha, coluna 0
data_x = teste_x[:, 0]
# todas as linha, coluna 1
data_y = teste_x[:, 1]

x_min = data_x.min()
x_max = data_x.max()
y_min = data_y.min()
y_max = data_y.max()


pixels = 100
eixo_x = np.arange(x_min, x_max, (x_max - x_min) / pixels)
eixo_y = np.arange(y_min, y_max, (y_max - y_min) / pixels)


xx, yy = np.meshgrid(eixo_x, eixo_y)
pontos = np.c_[xx.ravel(), yy.ravel()]


Z = modelo.predict(pontos)
Z = Z.reshape(xx.shape)


import matplotlib.pyplot as plt

plt.contourf(xx, yy, Z, alpha = 0.3)
plt.scatter(data_x, data_y, c = teste_y, s = 5)